# -week
伯禹打卡专用
## period one
### part one
  * 线性回归损失函数前有1/2，需注意。
  * 在多层感知机中引入激活函数的原因是，将多个无激活函数的线性层叠加起来，其表达能力与单个线性层相同
  * 权重矩阵包含偏移项  
### part two
  * L2范数正则化也就是权重衰减是用来应对过拟合的
  * 丢弃法（dropout）不改变输入期望值
  * 构建词典时，需要构建词到索引的双向映射
  * 随机采样中训练数据中的每个字符最多可以出现在一个样本中
  * 随机采样中每个样本只包含局部的时间序列信息，因为样本不完整所以每个批量需要重新初始化隐藏状态
